# RDPRM 2 - High-Level Architecture & File Structure

## Project Overview

RDPRM 2 is a **local development tool** that automates data extraction from two Quebec government registries:

1. **REQ (Registre des Entreprises du QuÃ©bec)** - Company registry
2. **RDPRM (Registre des droits personnels et rÃ©els mobiliers)** - Personal and movable property rights

**Purpose:** Research and data collection for due diligence on Quebec companies.

**Key Characteristic:** Designed for **local execution** with visible browser for debugging, NOT production server deployment.

## Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        User/Client                          â”‚
â”‚  (Creates search session, selects company names)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Supabase Database                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  search_sessions (parent)                           â”‚    â”‚
â”‚  â”‚    â†“                                                 â”‚    â”‚
â”‚  â”‚  selected_names_for_rdprm â”€[TRIGGER]â†’ rdprm_searchesâ”‚    â”‚
â”‚  â”‚                              (status: pending)       â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ Polls every 10s
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RDPRM Worker Process                      â”‚
â”‚                  (rdprm-worker.ts)                          â”‚
â”‚                                                              â”‚
â”‚  while (isRunning):                                         â”‚
â”‚    1. SELECT * FROM rdprm_searches WHERE status='pending'   â”‚
â”‚    2. UPDATE status='in_progress'                           â”‚
â”‚    3. Call scraper: scrapeFicheComplete()                   â”‚
â”‚    4. UPDATE status='completed' with storage_path           â”‚
â”‚    5. Check if session complete                             â”‚
â”‚    6. Sleep 10 seconds                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ Calls
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  RDPRM Scraper (lib/rdprm.ts)               â”‚
â”‚                                                              â”‚
â”‚  1. Launch Chromium (headless: false)                       â”‚
â”‚  2. Navigate + Login (networkidle waits)                    â”‚
â”‚  3. Search company                                          â”‚
â”‚  4. Download PDF (4 fallback strategies)                    â”‚
â”‚  5. Upload to Supabase Storage                              â”‚
â”‚  6. Return storage path                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Supabase Storage                          â”‚
â”‚                   Bucket: rdprm-documents                   â”‚
â”‚                                                              â”‚
â”‚  session-id-1/                                              â”‚
â”‚    â”œâ”€â”€ company_name_1.pdf                                   â”‚
â”‚    â”œâ”€â”€ company_name_2.pdf                                   â”‚
â”‚    â””â”€â”€ company_name_3.pdf                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## File Structure

```
/Users/marco/Documents/Dev/RDPRM 2/
â”‚
â”œâ”€â”€ ğŸ“„ Worker Entry Points (Main Processes)
â”‚   â”œâ”€â”€ rdprm-worker.ts         # RDPRM background worker (296 lines)
â”‚   â””â”€â”€ req-worker.ts           # REQ background worker (225 lines)
â”‚
â”œâ”€â”€ ğŸ“ lib/ (Core Library)
â”‚   â”œâ”€â”€ rdprm.ts                # RDPRM scraper automation (573 lines)
â”‚   â”œâ”€â”€ registre-entreprise.ts  # REQ scraper
â”‚   â”œâ”€â”€ html-cleaner.ts         # Parse/clean HTML (345 lines)
â”‚   â”œâ”€â”€ supabase.ts             # Database client (76 lines)
â”‚   â”œâ”€â”€ storage.ts              # File utilities (14 lines)
â”‚   â””â”€â”€ gemini.ts               # AI analysis
â”‚
â”œâ”€â”€ ğŸ“ supabase/ (Database Schema)
â”‚   â””â”€â”€ migrations/
â”‚       â”œâ”€â”€ 001_simplified_schema.sql
â”‚       â”œâ”€â”€ 002_add_cleaned_data.sql
â”‚       â”œâ”€â”€ 003_trigger_rdprm_on_name_selection.sql  # CRITICAL TRIGGER
â”‚       â”œâ”€â”€ 004_add_req_tracking.sql
â”‚       â”œâ”€â”€ 20250122000000_fix_rdprm_trigger.sql
â”‚       â””â”€â”€ 20250122010000_add_rdprm_storage.sql
â”‚
â”œâ”€â”€ ğŸ“ Test/Debug Scripts
â”‚   â”œâ”€â”€ test-rdprm-workflow.ts
â”‚   â”œâ”€â”€ test-registre.ts
â”‚   â”œâ”€â”€ debug-rdprm.ts
â”‚   â””â”€â”€ verify-database.ts
â”‚
â”œâ”€â”€ âš™ï¸ Configuration Files
â”‚   â”œâ”€â”€ package.json            # Dependencies (Playwright 1.48.0)
â”‚   â”œâ”€â”€ playwright.config.ts    # Browser configuration
â”‚   â”œâ”€â”€ tsconfig.json           # TypeScript config
â”‚   â”œâ”€â”€ .env.example            # Environment template
â”‚   â””â”€â”€ .env                    # Secrets (not committed)
â”‚
â””â”€â”€ ğŸ“ data/ (Local Storage)
    â””â”€â”€ Screenshots, downloads, session cache
```

## Component Purposes

### 1. Worker Files (Background Processes)

**rdprm-worker.ts** - Main RDPRM worker
- Polls `rdprm_searches` table every 10 seconds
- Processes pending searches one at a time
- Updates status: pending â†’ in_progress â†’ completed/failed/not_found
- Checks session completion after each search

**req-worker.ts** - REQ company search worker
- Polls `search_sessions` for pending company selections
- Uses BrowserBase (cloud browsers) for REQ scraping
- Stores results in `req_companies` table

### 2. Core Library Files

**lib/rdprm.ts** - Browser automation
- **573 lines** of Playwright automation
- Handles: login, navigation, search, PDF download
- 4-layer fallback strategy for PDF acquisition
- Returns storage path after upload

**lib/html-cleaner.ts** - Data extraction
- Parses raw HTML from REQ results
- Extracts structured data (administrators, fusions, etc.)
- Cleans and normalizes company information

**lib/supabase.ts** - Database client
- Initializes Supabase client with service role key
- Provides storage bucket access
- 76 lines of client setup

**lib/storage.ts** - File system utilities
- Ensures data directory exists
- Generates safe filenames from company names
- 14 lines of utility functions

### 3. Database Migrations

**Critical migration:** `003_trigger_rdprm_on_name_selection.sql`

Creates the automatic job creation trigger:
```sql
CREATE TRIGGER on_selected_name_insert
  AFTER INSERT ON selected_names_for_rdprm
  FOR EACH ROW
  EXECUTE FUNCTION trigger_rdprm_search_on_name_insert();
```

**Effect:** When a name is selected, a pending RDPRM search is automatically created.

### 4. Configuration Files

**package.json** - Key dependencies:
```json
{
  "dependencies": {
    "playwright": "1.48.0",              // Locked version
    "@supabase/supabase-js": "^2.76.1",
    "dotenv": "16.4.5"
  }
}
```

**playwright.config.ts** - Browser settings (likely default Playwright config)

**tsconfig.json** - TypeScript compilation with ES modules

**.env** - Runtime secrets:
```env
RDPRM_USER=DVA3
RDPRM_PASS=Rdprm123!!!
RDPRM_SEC=RDPRM
SUPABASE_URL=...
SUPABASE_SERVICE_ROLE_KEY=...
```

## Data Flow

### REQ Search Flow
```
User creates session
  â†’ REQ worker polls
  â†’ BrowserBase scrapes company results
  â†’ Stores in req_companies table
  â†’ User selects company
  â†’ Names extracted to selected_names_for_rdprm
  â†’ TRIGGER creates rdprm_searches
```

### RDPRM Search Flow
```
selected_names_for_rdprm INSERT
  â†’ TRIGGER creates rdprm_searches (pending)
  â†’ RDPRM worker polls (every 10s)
  â†’ Claims job (status: in_progress)
  â†’ Launches browser (headless: false)
  â†’ Login + Navigate + Search
  â†’ Download PDF (4 strategies)
  â†’ Upload to Supabase Storage
  â†’ Update rdprm_searches (status: completed, storage_path)
  â†’ Check if all session searches done
  â†’ If yes: search_sessions.status = completed
```

## Key Design Decisions

### 1. Local Execution Only
- `headless: false` - Visible browser for debugging
- `slowMo: 500` - Slowed down for human observation
- Runs on Mac with display (won't work on headless server)

### 2. Polling Architecture
- Simple polling loop (every 10 seconds)
- No job queue infrastructure (Redis, Bull, etc.)
- In-memory concurrency tracking only

### 3. Automatic Job Creation
- Database trigger eliminates manual job queuing
- Tight coupling between name selection and RDPRM search
- Fully automated workflow

### 4. Storage Organization
- Supabase Storage bucket: `rdprm-documents`
- Path structure: `{sessionId}/{companyName}.pdf`
- Private bucket (requires authentication)

### 5. Error Handling
- Three terminal states: completed, failed, not_found
- No automatic retry (manual intervention required)
- Error messages stored in database

## Scalability Limitations

1. **Single worker only** - `MAX_CONCURRENT=1` default
2. **No distributed locking** - Race conditions if multiple workers
3. **Visible browser required** - Can't run in containers/cloud
4. **Local file system** - Uses local directories for cache
5. **No monitoring** - Basic console logs only

## Why This Architecture Works for Development

âœ… **Advantages:**
- Simple to understand and debug
- Visible browser shows what's happening
- Direct database access (no queue complexity)
- Fast iteration during development

âŒ **Not Production-Ready Because:**
- Requires physical/virtual display
- Single worker = low throughput
- No horizontal scaling
- No monitoring/alerting
- No retry logic
- Tight coupling to local environment

## Summary

RDPRM 2 is a **well-designed local development tool** that demonstrates the complete workflow from company selection to PDF extraction. However, it was never intended for production server deployment.

Key strengths:
- Clean separation of concerns (worker, scraper, database)
- Robust PDF download with 4 fallback strategies
- Automatic job creation via database trigger
- Complete audit trail in database

Key limitations:
- Hardcoded to local execution (headless: false)
- No production infrastructure (monitoring, scaling, retry)
- Not designed for headless server environment

To adapt for production, you must:
1. Change to `headless: true`
2. Replace `networkidle` with `domcontentloaded + explicit waits`
3. **Keep `slowMo: 500`** (critical for website compatibility)
4. Add proper job locking for multi-worker deployment
5. Add monitoring and alerting
6. Implement retry logic
