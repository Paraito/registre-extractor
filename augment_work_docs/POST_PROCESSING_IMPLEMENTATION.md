# Post-Processing Workflow Implementation

## ğŸ“‹ Overview

This document describes the automated post-processing workflow for successfully completed extraction jobs in the registre-extractor system.

**Status**: âœ… **FULLY IMPLEMENTED**

The post-processing workflow was already implemented as the **OCR Monitor service**. This implementation adds the `boosted_file_content` column to properly separate raw and enhanced OCR text.

---

## ğŸ¯ Requirements (All Met)

### âœ… Trigger Condition
**Requirement**: When an extraction worker completes successfully (status_id = 3) AND has a supabase_path available AND the document_source = 'index', automatically trigger post-processing.

**Implementation**: The OCR Monitor polls the database every 10 seconds for documents matching:
```sql
SELECT * FROM extraction_queue
WHERE status_id = 3                    -- Extraction complete
  AND document_source = 'index'        -- Index documents only
  AND supabase_path IS NOT NULL        -- PDF available (validated in code)
  AND file_content IS NULL             -- Not yet processed
ORDER BY created_at ASC
LIMIT 1;
```

**Location**: `src/ocr/monitor.ts` lines 114-121

### âœ… Architecture
**Requirement**: Determine whether post-processing should be handled by existing extraction workers OR a new dedicated worker type.

**Decision**: **Separate dedicated OCR worker** (OCR Monitor service)

**Rationale**: See [ARCHITECTURE_DECISION.md](ARCHITECTURE_DECISION.md) for detailed analysis.

**Key Benefits**:
- Separation of concerns (web scraping vs text processing)
- Independent scalability
- Efficient resource utilization
- Failure isolation
- Different dependency management

### âœ… Queue System
**Requirement**: Implement a queuing system similar to the existing extraction queue.

**Implementation**: Uses the same `extraction_queue` table as a message queue:
- Polls database every 10 seconds (configurable via `OCR_POLL_INTERVAL_MS`)
- Processes one document per poll cycle
- Updates status when complete
- Automatic retry on failure (documents remain in queue)

**Location**: `src/ocr/monitor.ts`

### âœ… Database Schema Changes
**Requirement**: Add `boosted_file_content` column to store enhanced/processed version, while `file_content` stores raw/original content.

**Implementation**: 
- Migration `004_add_boosted_file_content.sql` adds the new column
- `file_content`: Stores raw OCR text (unprocessed Gemini Vision output)
- `boosted_file_content`: Stores enhanced text with 60+ correction rules applied
- Both columns are TEXT type with full-text search indexes

**Location**: `supabase/migrations/004_add_boosted_file_content.sql`

---

## ğŸ—ï¸ Architecture

### System Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Extraction Queue                         â”‚
â”‚                   (Database Table)                          â”‚
â”‚                                                             â”‚
â”‚  Columns:                                                   â”‚
â”‚  â€¢ status_id (1=waiting, 2=processing, 3=complete, 5=done) â”‚
â”‚  â€¢ document_source ('index', 'acte', 'plan_cadastraux')    â”‚
â”‚  â€¢ supabase_path (PDF URL)                                 â”‚
â”‚  â€¢ file_content (raw OCR text)                             â”‚
â”‚  â€¢ boosted_file_content (enhanced OCR text)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                          â”‚
               â”‚                          â”‚
               â–¼                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Extraction Workers     â”‚  â”‚     OCR Monitor          â”‚
â”‚                          â”‚  â”‚                          â”‚
â”‚ â€¢ Web scraping           â”‚  â”‚ â€¢ PDF download           â”‚
â”‚ â€¢ PDF extraction         â”‚  â”‚ â€¢ Image conversion       â”‚
â”‚ â€¢ Browser automation     â”‚  â”‚ â€¢ Gemini Vision AI       â”‚
â”‚ â€¢ Upload to storage      â”‚  â”‚ â€¢ Text extraction        â”‚
â”‚                          â”‚  â”‚ â€¢ Boost corrections      â”‚
â”‚ Status: 1 â†’ 2 â†’ 3        â”‚  â”‚                          â”‚
â”‚                          â”‚  â”‚ Status: 3 â†’ 5            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

```
1. Extraction Worker
   â”œâ”€ Polls for status_id = 1 (EN_ATTENTE)
   â”œâ”€ Extracts PDF from Quebec Land Registry
   â”œâ”€ Uploads to Supabase Storage
   â””â”€ Updates: status_id = 3, supabase_path = <url>

2. OCR Monitor (Post-Processing)
   â”œâ”€ Polls for status_id = 3, document_source = 'index', file_content IS NULL
   â”œâ”€ Downloads PDF from Supabase Storage
   â”œâ”€ Converts PDF to PNG (300 DPI)
   â”œâ”€ Extracts text with Gemini Vision AI â†’ raw text
   â”œâ”€ Applies 60+ correction rules â†’ boosted text
   â””â”€ Updates: 
       â€¢ file_content = raw text
       â€¢ boosted_file_content = boosted text
       â€¢ status_id = 5 (EXTRACTION_COMPLETE)
```

### Status Flow

```
1 (En attente)
    â†“
    [Extraction Worker picks up job]
    â†“
2 (En traitement)
    â†“
    [Extraction completes, PDF uploaded]
    â†“
3 (ComplÃ©tÃ©)
    â†“
    [OCR Monitor picks up job]
    â†“
    [OCR processing: extract + boost]
    â†“
5 (Extraction ComplÃ©tÃ©)
```

---

## ğŸ“¦ Implementation Details

### Files Modified/Created

#### Database Migrations
- âœ… `supabase/migrations/004_add_boosted_file_content.sql` - Adds boosted_file_content column

#### TypeScript Types
- âœ… `src/types/index.ts` - Added boosted_file_content to ExtractionQueueJob interface

#### OCR Monitor
- âœ… `src/ocr/monitor.ts` - Updated to store both raw and boosted text

#### Documentation
- âœ… `ARCHITECTURE_DECISION.md` - Architecture rationale and analysis
- âœ… `SERVER_CAPACITY.md` - Detailed server capacity analysis
- âœ… `POST_PROCESSING_IMPLEMENTATION.md` - This file
- âœ… `OCR_INTEGRATION.md` - Updated to reflect new column

### Code Changes

**Before** (`src/ocr/monitor.ts`):
```typescript
// Only stored boosted text
const fileContent = ocrResult.boostedText;

await client.from('extraction_queue').update({
  file_content: fileContent,
  status_id: EXTRACTION_STATUS.EXTRACTION_COMPLETE,
}).eq('id', document.id);
```

**After** (`src/ocr/monitor.ts`):
```typescript
// Store both raw and boosted text
const rawText = ocrResult.rawText;
const boostedText = ocrResult.boostedText;

await client.from('extraction_queue').update({
  file_content: rawText,              // Raw OCR output
  boosted_file_content: boostedText,  // Enhanced with corrections
  status_id: EXTRACTION_STATUS.EXTRACTION_COMPLETE,
}).eq('id', document.id);
```

---

## ğŸš€ Deployment

### Prerequisites

1. **Gemini API Key**
   ```bash
   # Add to .env
   GEMINI_API_KEY=your-api-key-here
   ```

2. **PDF Conversion Tools**
   ```bash
   # macOS
   brew install imagemagick poppler
   
   # Ubuntu/Debian
   sudo apt-get install imagemagick poppler-utils
   ```

3. **Apply Database Migration**
   ```bash
   # Apply migration 004
   supabase db push
   ```

### Running the OCR Monitor

```bash
# Development mode (with auto-reload)
npm run ocr:dev

# Production mode
npm run build
npm run ocr
```

### Docker Deployment

The OCR Monitor can be deployed as a separate container:

```yaml
# docker-compose.yml
services:
  ocr-monitor:
    build: .
    command: npm run ocr
    environment:
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - OCR_POLL_INTERVAL_MS=10000
      - OCR_TEMP_DIR=/tmp/ocr-processing
    volumes:
      - ocr-temp:/tmp/ocr-processing
    restart: unless-stopped
```

---

## ğŸ“Š Server Capacity Analysis

See [SERVER_CAPACITY.md](SERVER_CAPACITY.md) for detailed analysis.

### Quick Summary

**Per OCR Worker**:
- **CPU**: 1-2 cores
- **RAM**: 1-2 GB
- **Disk**: 500MB-1GB temporary storage
- **Throughput**: 200-300 documents/hour

**Scaling**:
| Workers | CPU | RAM | Throughput (docs/hr) |
|---------|-----|-----|----------------------|
| 1 | 2 | 2GB | 200-300 |
| 2 | 4 | 4GB | 400-600 |
| 4 | 8 | 8GB | 800-1200 |

**Cost** (monthly):
- Infrastructure: ~$15-20 per worker
- API: ~$0.001 per document
- Total: ~$26 for 10K docs/month

---

## ğŸ§ª Testing

### Manual Testing

1. **Create a test index job**:
   ```bash
   tsx src/create-test-job-index.ts
   ```

2. **Start extraction worker** (if not running):
   ```bash
   npm run dev
   ```

3. **Wait for extraction to complete** (status_id = 3)

4. **Start OCR monitor**:
   ```bash
   npm run ocr:dev
   ```

5. **Verify in database**:
   ```sql
   SELECT 
     id,
     document_number,
     status_id,
     LENGTH(file_content) as raw_length,
     LENGTH(boosted_file_content) as boosted_length,
     updated_at
   FROM extraction_queue
   WHERE document_source = 'index'
     AND status_id = 5
   ORDER BY updated_at DESC
   LIMIT 5;
   ```

### Automated Testing

```bash
npm run test:ocr
```

---

## ğŸ“ˆ Monitoring

### Key Metrics

**Queue Depth** (documents waiting for OCR):
```sql
SELECT COUNT(*) FROM extraction_queue 
WHERE status_id = 3 
  AND document_source = 'index' 
  AND file_content IS NULL;
```

**Processing Rate** (documents/hour):
```sql
SELECT COUNT(*) FROM extraction_queue 
WHERE status_id = 5 
  AND updated_at > NOW() - INTERVAL '1 hour';
```

**Error Rate**:
```sql
SELECT COUNT(*) FROM extraction_queue 
WHERE error_message LIKE '%OCR%' 
  AND updated_at > NOW() - INTERVAL '1 hour';
```

### Alerts

- Queue depth > 1000 â†’ Add more workers
- Processing rate < 100/hour â†’ Check worker health
- Error rate > 5% â†’ Investigate errors

---

## ğŸ‰ Summary

The automated post-processing workflow is **fully implemented and operational**:

âœ… **Trigger Condition**: Automatically processes documents with status_id=3, document_source='index', supabase_path available  
âœ… **Architecture**: Separate OCR Monitor worker for optimal resource management  
âœ… **Queue System**: Database-backed queue with automatic polling  
âœ… **Database Schema**: Added boosted_file_content column to separate raw and enhanced text  
âœ… **Documentation**: Complete architecture decision and capacity analysis  

**To use**:
1. Ensure `GEMINI_API_KEY` is configured
2. Apply database migration: `supabase db push`
3. Run OCR monitor: `npm run ocr:dev` or `npm run ocr`
4. Monitor logs and database for processing status

The system will automatically process all completed index document extractions!

